/**
 * qbuffer -- buffered binary datastream for piping, buffering and rechunking
 * Simpler, non-piped version.
 *
 * Copyright (C) 2015 Andras Radics
 * Licensed under the Apache License, Version 2.0
 *
 * 2015-09-15 - AR.
 */


'use strict'


function QBuffer( opts ) {
    if (this === global || !this) return new QBuffer(opts)
    opts = opts || {}
    this.highWaterMark = opts.highWaterMark || 1024000
    this.lowWaterMark = opts.lowWaterMark || 40960
    this.encoding = opts.encoding || undefined
    this.start = 0
    this.length = 0
    this.chunks = new Array()

    // default records are newline terminated strings
    this.setDelimiter("\n")

    this._wrapClass()

    return this
}
util.inherits(QBuffer, EventEmitter)

var QBuffer_prototype = {
    highWaterMark: null,
    lowWaterMark: null,
    encoding: undefined,                // node default is 'utf8'
    start: 0,
    length: 0,
    _nextLine: -1,                      // cached _lineEnd(), cleared by _skipbytes(), unget() and setDelimiter()

    chunks: null,
    paused: true,                       // output paused explicitly by the user (to stop 'data' events)
    overfull: false,                    // buffer over capacity, asked writers to throttle
    ended: false,                       // when end() has been called
    _wrapClass: function() {},          // to extend the class (TBD)

    _computeLineEnd: null,              // find nbytes to end of next record, set by setDelimiter()

    // return the end of the next record in the data, or -1 if not yet known
    _lineEnd:
    function _lineEnd( ) {
        if (this._nextLine >= 0) return this._nextLine
        return this._nextLine = this._computeLineEnd()
    },

    _delimiterFunc: null,

    setDelimiter:
    function setDelimiter( delimiter ) {
        this._nextLine = -1
        switch (true) {
        case delimiter === null:
        case delimiter === undefined:
            // on unspecified or empty delimiter restore the default, newline terminated strings
            delete this._computeLineEnd
            break
        case typeof delimiter === 'string':
            var ch1 = delimiter.charCodeAt(0), ch2 = delimiter.charCodeAt(1)
            if (delimiter.length === 1) this._computeLineEnd = function() {
                var eol = this._indexOfCharcode(ch1, this.start)
                return eol === -1 ? -1 : eol + 1 - this.start
            }
            else if (delimiter.length === 2) this._computeLineEnd = function() {
                var eol = this._indexOfCharcode(ch1, ch2, this.start)
                return eol === -1 ? -1 : eol + 2 - this.start
            }
            else throw new Error("string delimiters longer than 2 chars not supported yet")
            break
        case typeof delimiter === 'function':
            var self = this
            this._delimiterFunc = delimiter
            this._computeLineEnd = function() {
                // computed record end returns a user-visible start-relative offset
                var eol = self._delimiterFunc()
                return eol === -1 ? -1 : eol
            }
            break
        case typeof delimiter === 'number':
            this._computeLineEnd = function() { return delimiter }
            break
        default:
            throw new Error("unrecognized record delimiter: " + (typeof delimiter))
            break
        }
        return this
    },

    indexOfChar:
    function indexOfChar( char, char2, start ) {
        var pos = (start === undefined)
            ? this._indexOfCharcode(char.charCodeAt(0), (char2 || 0) + this.start)
            : this._indexOfCharcode(char.charCodeAt(0), char2.charCodeAt(0), (start || 0) + this.start)
        return pos === -1 ? -1 : pos - this.start
    },

    // push data back onto the head of the queue
    unget:
    function unget( chunk, encoding ) {
        this._nextLine = -1
        if (this.start > 0) { this.chunks[0] = this.chunks[0].slice(this.start) ; this.start = 0 }
        if (!Buffer.isBuffer(chunk)) chunk = new Buffer(chunk, encoding || this.encoding)
        this.chunks.unshift(chunk)
        this.length += chunk.length
        // TODO: what to return?
    },

    // retrieve the next record (newline-terminated string) form the buffer
    getline:
    function getline( ) {
        var nbytes = this._lineEnd()
        return (nbytes === -1) ? null : this.read(nbytes)
    },

    // return, but do not consume, the next record from the buffer
    peekline:
    function peekline( ) {
        var nbytes = this._lineEnd()
        return (nbytes === -1) ? null : this.peekbytes(nbytes, this.encoding)
    },

    // return the requested number of bytes or null if not that many, or everything in the buffer
    read:
    function read( nbytes, encoding, cb ) {
        if (!cb && typeof encoding === 'function') { cb = encoding ; encoding = null }
        if (!cb && !encoding && typeof nbytes === 'function') { cb = nbytes ; nbytes = this.length }
        // TODO: if callback provided and no data yet, queue reader and complete read later
        // TODO: actually invoke callback TBD

        if (!nbytes) nbytes = this.length
        var ret = this.peekbytes(nbytes, encoding)
        if (ret !== null) this.skipbytes(nbytes)
        return ret
    },

    peekbytes:
    function peekbytes( nbytes, encoding ) {
        if (!this.chunks.length && nbytes) return null
        var bound = nbytes + this.start
        if (bound > this.start + this.length) return null
        if (bound > this.chunks[0].length) {
            // _concat: merge Buffers until bound is contained inside the first buffer
            var chunks = this.chunks, nchunks = 0, combinedLength = 0
            // find the number of chunks needed for nbytes of data
            while (combinedLength < bound) { nchunks += chunks[nchunks].length ; nchunks += 1 }
            // replace the first nchunks chunks with their merged contents, using a temporary placeholder
            var chunk = Buffer.concat(chunks.splice(0, nchunks, ['placeholder']))
            chunks[0] = chunk
            // TODO: timeit: might be faster to just shift off the chunks and copy into a preallocated Buffer
        }
        var chunk = this.chunks[0]
        if (!chunk) return null
        return encoding ? chunk.toString(encoding, this.start, bound) : chunk.slice(this.start, bound)
    },

    // append data to the buffered contents
    write:
    function write( chunk, encoding, cb ) {
        if (!cb && typeof encoding === 'function') { cb = encoding ; encoding = undefined }
        if (this.ended) {
            var err = new Error("write after end")
            if (cb) return cb(err)
            else throw err
        }
        if (!Buffer.isBuffer(chunk)) chunk = new Buffer(chunk, encoding || this.encoding)
        this.chunks.push(chunk)
        this.length += chunk.length

        if (cb) cb(null, chunk.length)

        // return true if willing to buffer more, false to throttle input
        // automatic throttling requires knowing the record boundaries! (ie setDelimiter),
        // otherwise might deadlock waiting for the paused data to finish arriving
        // only when we already have the next record for getline() can we throttle
        if (this.length > this.highWaterMark && this._lineEnd() >= 0) {
            this.overfull = true
            return false
        }
        return true
    },

    end:
    function end( chunk, encoding, cb ) {
        if (chunk !== null && chunk !== undefined) this.write(chunk, encoding)
        this.ended = true
        // drain again to end() the output stream (even though the write() just did)
        //this._drain()
        // FIXME: wait for output to be fully drained, then emit 'finish' and invoke callback
        // this.emitter.once('finish', cb)
    },

    pipeFrom:
    function pipeFrom( stream ) {
        var self = this
        var onData, onEnd, onClose
        stream.on('data', onData = function onData(chunk) { self.write(chunk) })
        stream.once('end', onEnd = function() { stream.emit('_unpipeFrom') })
        stream.once('close', onClose = function() { stream.emit('_unpipeFrom') })
        stream.once('_unpipeFrom', function() {
            stream.removeListener('data', onData)
            stream.removeListener('end', onEnd)
            stream.removeListener('close', onClose)
        })
    },

    // find the offset of the first char in the buffered data
    // usage: ioc(code), ioc(code, start), ioc(code, code2, start)
    _indexOfCharcode:
    function _indexOfCharcode( code, code2, start ) {
        // must be called with start >= this.start
        if (start === undefined) { start = code2; code2 = undefined }
        start = start || this.start
        var i, j, offset = 0, chunk
        for (i=0; i<this.chunks.length; i++) {
            chunk = this.chunks[i]
            if (start >= chunk.length) {
                // advance to the chunk containing start
                start -= chunk.length
                offset += chunk.length
            }
            else {
                if (code2 === undefined) {
                    for (j=start; j<chunk.length; j++) {
                        // then scan that chunk for the first instance of code
                        if (chunk[j] === code) return offset + j
                    }
                }
                else {
                    for (j=start; j<chunk.length; j++) {
                        // NOTE: testing for a second charcode slows getline() 40%, use separate loop
                        if (chunk[j] === code) {
                            if (chunk.length > j + 1 && chunk[j+1] === code2) return offset + j
                            if (chunk.length === j + 1 && this.chunks.length > i + 1 && this.chunks[i+1][0] === code2) return offset + j
                        }
                    }
                }
                // if scanned a chunk, scan the next from its very beginning
                offset += chunk.length
                start = 0
            }
        }
        return -1
    },

    // skip past and discard all buffered bytes until bound
    skipbytes:
    function skipbytes( nbytes ) {
        this._nextLine = -1
        var bound = nbytes + this.start
        while (this.length > 0) {
            if (bound >= this.chunks[0].length) {
                var chunk = this.chunks.shift()
                bound -= chunk.length
                this.length -= (chunk.length - this.start)
                this.start = 0
            }
            else {
                this.length -= (bound - this.start)
                this.start = bound
                if (this.start > 100000 && this.chunks[0].length - this.start < this.start) {
                    // do not let the first buffer grow without bound, trim it back periodically
                    this.chunks[0] = this.chunks[0].slice(this.start)
                    this.start = 0
                }
                if (this.overfull && this.length < this.lowWaterMark) { this.overfull = false }
                return
            }
        }
    },
}

for (var i in QBuffer_prototype) QBuffer.prototype[i] = QBuffer_prototype[i]
// NOTE: reads lines 2.5x faster if methods not poked singly into prototype
// so do not inherit, much faster to delegate the EventEmitter methods

// NOTE: but assigning prototype to self speeds accesses back up!
QBuffer.prototype = QBuffer.prototype

//QBuffer.prototype = QBuffer_prototype

module.exports = QBuffer
